# backend/app/services/prompt_generator.py
import json
from typing import List, Dict, Any, Tuple
from ..schemas.chat import UserStateSummary, SentimentAnalysisResult
from ..schemas.content import CodeContent


class PromptGenerator:
    """æç¤ºè¯ç”Ÿæˆå™¨"""

    def __init__(self):
        self.base_system_prompt = """
"You are 'Alex', a world-class AI programming tutor. Your goal is to help a student master a specific topic by providing personalized, empathetic, and insightful guidance. You must respond in Markdown format.

## STRICT RULES
Be an approachable-yet-dynamic teacher, who helps the user learn by guiding them through their studies.
1.  Get to know the user. If you don't know their goals or grade level, ask the user before diving in. (Keep this lightweight!) If they don't answer, aim for explanations that would make sense to a 10th grade student.
2.  Build on existing knowledge. Connect new ideas to what the user already knows.
3.  Guide users, don't just give answers. Use questions, hints, and small steps so the user discovers the answer for themselves.
4.  Check and reinforce. After hard parts, confirm the user can restate or use the idea. Offer quick summaries, mnemonics, or mini-reviews to help the ideas stick.
5.  Vary the rhythm. Mix explanations, questions, and activities (like role playing, practice rounds, or asking the user to teach you) so it feels like a conversation, not a lecture.

Above all: DO NOT DO THE USER'S WORK FOR THEM. Don't answer homework questions - help the user find the answer, by working with them collaboratively and building from what they already know.
"""
        
        # ç»Ÿä¸€æç¤ºè¯æ¨¡ç‰ˆ
        self.debug_prompt_template = """
# Role
You are an experienced programming tutor who uses the Socratic teaching method. Your core goal is to stimulate students' independent thinking ability, guiding them to find and solve problems on their own, rather than directly providing ready-made answers.

# Core Principles
You will receive a number called `question_count`, which represents how many times the student has asked for help on this current problem.
Please treat `question_count` as a key indicator of the student's level of confusion.

Your teaching strategy must be progressive:
- **When `question_count` is low**, your response should be inspiring and high-level. Use more questioning methods to guide students to examine their code and thinking.
- **As `question_count` increases**, it indicates that the student may be stuck in a difficult situation, and your hints should become more specific and targeted. You can guide students to focus on specific code areas or logic.
- **When `question_count` becomes very high**, this means the student may be very frustrated, and providing direct answers and detailed explanations is reasonable and necessary to help them break through the difficulty and learn from it.

# Task
Now, the student is working on the "{content_title}" task. They have encountered a problem, and this is their **{question_count}** time asking about it.
Here is their code and the error they encountered:

**Student Code:**
```python
{user_code}
```

**Error Message:**
```
{error_message}
```

Please generate the most appropriate response for the student based on your role as a tutor and the core principles above.
"""

        # å­¦ä¹ æ¨¡å¼æç¤ºè¯æ¨¡ç‰ˆ
        self.learning_prompt_template = """
# Role
You are an experienced programming tutor specializing in guided learning. Your core goal is to help students deeply understand programming concepts through structured explanation, practical examples, and interactive guidance.

# Core Principles
You will receive the student's current mastery level and learning context for the topic "{content_title}".
Your teaching approach should be adaptive and comprehensive:

- **For beginner students** (mastery â‰¤ 0.5): Start with fundamental concepts, use simple analogies, and provide step-by-step explanations. Focus on building confidence and foundational understanding.
- **For intermediate students** (0.5 < mastery â‰¤ 0.8): Build on existing knowledge, introduce more complex examples, and encourage exploration of related concepts. Connect new ideas to what they already know.
- **For advanced students** (mastery > 0.8): Provide challenging content, explore advanced applications, and encourage critical thinking. Discuss best practices, optimization techniques, and real-world scenarios.

# Teaching Strategy
1. **Concept Introduction**: Clearly explain the core concept and its importance
2. **Practical Examples**: Provide relevant code examples that demonstrate the concept
3. **Interactive Learning**: Ask thought-provoking questions to engage the student
4. **Real-world Application**: Show how the concept applies to actual programming scenarios
5. **Common Pitfalls**: Highlight frequent mistakes and how to avoid them
6. **Practice Suggestions**: Recommend exercises or projects to reinforce learning

# Current Context
**Topic**: {content_title}
**Student's Current Mastery Level**: {mastery_level} (probability: {mastery_prob:.2f})
**Learning Mode**: The student is actively studying and seeking to understand this concept

Please provide a comprehensive, engaging learning experience that helps the student master this topic at their appropriate level.
"""

    def create_prompts(
        self,
        user_state: UserStateSummary,
        retrieved_context: List[str],
        conversation_history: List[Dict[str, str]],
        user_message: str,
        code_content: CodeContent = None,
        mode: str = None,
        content_title: str = None,
        content_json: str = None,
        test_results: List[Dict[str, Any]] = None
    ) -> Tuple[str, List[Dict[str, str]]]:
        """
        åˆ›å»ºå®Œæ•´çš„æç¤ºè¯å’Œæ¶ˆæ¯åˆ—è¡¨

        Args:
            user_state: ç”¨æˆ·çŠ¶æ€æ‘˜è¦
            retrieved_context: RAGæ£€ç´¢çš„ä¸Šä¸‹æ–‡
            conversation_history: å¯¹è¯å†å²
            user_message: ç”¨æˆ·å½“å‰æ¶ˆæ¯
            code_content: ä»£ç ä¸Šä¸‹æ–‡
            mode: æ¨¡å¼ ("learning" æˆ– "test")
            content_title: å†…å®¹æ ‡é¢˜
            content_json: å†…å®¹çš„JSONå­—ç¬¦ä¸²

        Returns:
            Tuple[str, List[Dict[str, str]]]: (system_prompt, messages)
        """
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = self._build_system_prompt(
            user_state=user_state,
            retrieved_context=retrieved_context,
            mode=mode,
            content_title=content_title,
            content_json=content_json,
            test_results=test_results,
            code_content=code_content
        )

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = self._build_message_history(
            conversation_history=conversation_history,
            code_context=code_content,
            user_message=user_message
        )

        return system_prompt, messages

def _get_coding_behavior_analysis(self, user_state: UserStateSummary) -> str:
    """ç”Ÿæˆç¼–ç¨‹è¡Œä¸ºåˆ†ææç¤º"""
    if not hasattr(user_state, 'behavior_patterns'):
        return ""
    
    patterns = user_state.behavior_patterns
    analysis_parts = []
    
    # ç¼–è¾‘ç»Ÿè®¡ä¿¡æ¯
    edit_stats = patterns.get('edit_statistics', {})
    if edit_stats:
        analysis_parts.append("## ä»£ç ç¼–è¾‘ç»Ÿè®¡")
        analysis_parts.append(f"- **æ€»ç¼–è¾‘æ¬¡æ•°**: {edit_stats.get('total_edits', 0)}")
        analysis_parts.append(f"- **HTMLç¼–è¾‘**: {edit_stats.get('html_edits', 0)}æ¬¡")
        analysis_parts.append(f"- **CSSç¼–è¾‘**: {edit_stats.get('css_edits', 0)}æ¬¡") 
        analysis_parts.append(f"- **JSç¼–è¾‘**: {edit_stats.get('js_edits', 0)}æ¬¡")
        analysis_parts.append(f"- **å¹³å‡ç¼–è¾‘è§„æ¨¡**: {edit_stats.get('avg_edit_size', 0):.1f}å­—ç¬¦")
        analysis_parts.append(f"- **é—®é¢˜é¢‘ç‡**: {edit_stats.get('problem_frequency', 0):.1%}")
    
    # åˆ†æå…·ä½“ç¼–è¾‘æ¨¡å¼ï¼ˆä½¿ç”¨æ–°å­—æ®µï¼‰
    significant_edits = patterns.get('significant_edits', [])
    if significant_edits:
        analysis_parts.append("\n## ç¼–è¾‘æ¨¡å¼åˆ†æ")
        
        # åˆ†ææœ€è¿‘20æ¬¡ç¼–è¾‘çš„åˆ é™¤å’Œæ·»åŠ æ¨¡å¼
        recent_edits = significant_edits[-20:]
        total_deleted = sum(edit.get('deleted_chars', abs(edit.get('net_change', 0)) if edit.get('net_change', 0) < 0 else 0) 
                          for edit in recent_edits)
        total_added = sum(edit.get('added_chars', edit.get('net_change', 0)) if edit.get('net_change', 0) > 0 else 0 
                        for edit in recent_edits)
        net_change = total_added - total_deleted
        
        analysis_parts.append(f"- **æœ€è¿‘{len(recent_edits)}æ¬¡ç¼–è¾‘**: åˆ é™¤ {total_deleted} å­—ç¬¦, æ–°å¢ {total_added} å­—ç¬¦")
        analysis_parts.append(f"- **å‡€å˜åŒ–**: {net_change} å­—ç¬¦")
        
        # åˆ†æç¼–è¾‘ç±»å‹åˆ†å¸ƒ
        edit_types = {}
        for edit in recent_edits:
            edit_type = edit.get('edit_type', 'unknown')
            edit_types[edit_type] = edit_types.get(edit_type, 0) + 1
        
        if edit_types:
            type_desc = ", ".join([f"{k}: {v}æ¬¡" for k, v in edit_types.items()])
            analysis_parts.append(f"- **ç¼–è¾‘ç±»å‹åˆ†å¸ƒ**: {type_desc}")
    
    # æœ€è¿‘é—®é¢˜åˆ†æ
    coding_problems = patterns.get('coding_problems', [])
    if coding_problems:
        analysis_parts.append("\n## æœ€è¿‘ç¼–ç¨‹é—®é¢˜")
        recent_problems = coding_problems[-5:]  # æœ€è¿‘5ä¸ªé—®é¢˜
        
        for i, problem in enumerate(recent_problems, 1):
            editor = problem.get('editor', 'unknown')
            consecutive_edits = problem.get('consecutive_edits', 0)
            severity = problem.get('severity', 'unknown')
            net_change = problem.get('net_change', 0)
            
            # ä½¿ç”¨æ–°å­—æ®µå¦‚æœå¯ç”¨
            deleted_chars = problem.get('deleted_chars')
            added_chars = problem.get('added_chars')
            
            if deleted_chars is not None and added_chars is not None:
                problem_desc = (
                    f"{i}. **{editor}ç¼–è¾‘å™¨**: {consecutive_edits}æ¬¡è¿ç»­ç¼–è¾‘, "
                    f"ä¸¥é‡ç¨‹åº¦: {severity}, åˆ é™¤: {deleted_chars}å­—ç¬¦, æ–°å¢: {added_chars}å­—ç¬¦"
                )
            else:
                problem_desc = (
                    f"{i}. **{editor}ç¼–è¾‘å™¨**: {consecutive_edits}æ¬¡è¿ç»­ç¼–è¾‘, "
                    f"ä¸¥é‡ç¨‹åº¦: {severity}, å‡€å˜åŒ–: {net_change}å­—ç¬¦"
                )
            
            analysis_parts.append(problem_desc)
    
    # ç¼–è¾‘æ¨¡å¼è¯¦ç»†åˆ†æ
    if significant_edits:
        analysis_parts.append("\n## è¯¦ç»†ç¼–è¾‘åˆ†æ")
        
        # åˆ†æå„ç¼–è¾‘å™¨çš„ç¼–è¾‘ä¹ æƒ¯
        editor_stats = {}
        for edit in significant_edits[-20:]:  # åˆ†ææœ€è¿‘20ä¸ªç¼–è¾‘
            editor = edit.get('editor', 'unknown')
            if editor not in editor_stats:
                editor_stats[editor] = {
                    'count': 0, 
                    'total_deleted': 0, 
                    'total_added': 0,
                    'types': {}
                }
            
            editor_stats[editor]['count'] += 1
            
            # ä½¿ç”¨æ–°å­—æ®µå¦‚æœå¯ç”¨ï¼Œå¦åˆ™å›é€€åˆ°æ—§å­—æ®µ
            deleted = edit.get('deleted_chars')
            if deleted is None and edit.get('net_change', 0) < 0:
                deleted = abs(edit.get('net_change', 0))
            
            added = edit.get('added_chars') 
            if added is None and edit.get('net_change', 0) > 0:
                added = edit.get('net_change', 0)
            
            if deleted is not None:
                editor_stats[editor]['total_deleted'] += deleted
            if added is not None:
                editor_stats[editor]['total_added'] += added
            
            edit_type = edit.get('edit_type', 'unknown')
            editor_stats[editor]['types'][edit_type] = editor_stats[editor]['types'].get(edit_type, 0) + 1
        
        for editor, stats in editor_stats.items():
            if stats['count'] > 0:
                avg_deleted = stats['total_deleted'] / stats['count'] if stats['total_deleted'] > 0 else 0
                avg_added = stats['total_added'] / stats['count'] if stats['total_added'] > 0 else 0
                type_desc = ", ".join([f"{k}:{v}æ¬¡" for k, v in stats['types'].items()])
                
                analysis_parts.append(
                    f"- **{editor}**: {stats['count']}æ¬¡ç¼–è¾‘, "
                    f"å¹³å‡åˆ é™¤: {avg_deleted:.1f}å­—ç¬¦, å¹³å‡æ–°å¢: {avg_added:.1f}å­—ç¬¦, {type_desc}"
                )
    
    # å­¦ä¹ è¡Œä¸ºå»ºè®®
    if analysis_parts:
        analysis_parts.append("\n## æ•™å­¦å»ºè®®")
        
        # åŸºäºé—®é¢˜é¢‘ç‡çš„å»ºè®®
        problem_freq = edit_stats.get('problem_frequency', 0)
        if problem_freq > 0.3:
            analysis_parts.append("- ğŸ“‰ å­¦ç”Ÿé‡åˆ°è¾ƒå¤šç¼–ç¨‹é—®é¢˜ï¼Œéœ€è¦æ›´å¤šåŸºç¡€æ¦‚å¿µè®²è§£å’Œåˆ†æ­¥æŒ‡å¯¼")
        elif problem_freq > 0.1:
            analysis_parts.append("- âš ï¸ å­¦ç”Ÿé‡åˆ°ä¸€äº›ç¼–ç¨‹é—®é¢˜ï¼Œå»ºè®®æä¾›é’ˆå¯¹æ€§æç¤ºå’Œç¤ºä¾‹")
        else:
            analysis_parts.append("- âœ… å­¦ç”Ÿç¼–ç¨‹è¿›å±•é¡ºåˆ©ï¼Œå¯ä»¥é€‚å½“å¢åŠ æŒ‘æˆ˜æ€§å†…å®¹")
        
        # åŸºäºç¼–è¾‘å™¨ä½¿ç”¨æƒ…å†µçš„å»ºè®®
        html_edits = edit_stats.get('html_edits', 0)
        css_edits = edit_stats.get('css_edits', 0) 
        js_edits = edit_stats.get('js_edits', 0)
        
        if js_edits > (html_edits + css_edits) * 2:
            analysis_parts.append("- ğŸ” å­¦ç”Ÿä¸“æ³¨äºJavaScripté€»è¾‘ï¼Œå¯èƒ½éœ€è¦HTML/CSSåŸºç¡€æ”¯æŒ")
        elif html_edits > (css_edits + js_edits) * 2:
            analysis_parts.append("- ğŸ¨ å­¦ç”Ÿä¸“æ³¨äºHTMLç»“æ„ï¼Œå¯èƒ½éœ€è¦CSSæ ·å¼å’ŒJavaScriptäº¤äº’æŒ‡å¯¼")
        
        # åŸºäºç¼–è¾‘æ¨¡å¼çš„åˆ†æ
        if any('edit_cycle' in str(edit.get('edit_type')) for edit in significant_edits[-10:]):
            analysis_parts.append("- ğŸ’ª å­¦ç”Ÿæœ‰è°ƒè¯•å’Œé‡å†™è¡Œä¸ºï¼Œè¡¨æ˜åœ¨å°è¯•è§£å†³é—®é¢˜ï¼Œåº”é¼“åŠ±è¿™ç§ persistence")
        
        # åŸºäºåˆ é™¤/æ·»åŠ æ¯”ä¾‹çš„å»ºè®®
        if significant_edits:
            recent_edits = significant_edits[-10:]
            total_deleted_recent = sum(edit.get('deleted_chars', 0) for edit in recent_edits)
            total_added_recent = sum(edit.get('added_chars', 0) for edit in recent_edits)
            
            if total_deleted_recent > total_added_recent * 1.5:
                analysis_parts.append("- ğŸ—‘ï¸ å­¦ç”Ÿå¤§é‡åˆ é™¤ä»£ç ï¼Œå¯èƒ½é‡åˆ°è®¾è®¡é—®é¢˜æˆ–ç†è§£å›°éš¾")
            elif total_added_recent > total_deleted_recent * 2:
                analysis_parts.append("- âœï¸ å­¦ç”Ÿç§¯æç¼–å†™ä»£ç ï¼Œå­¦ä¹ åŠ¨åŠ›è¾ƒå¼ºï¼Œå¯ä»¥ç»™äºˆæ›´å¤šåˆ›é€ æ€§ä»»åŠ¡")
    
    return "\n".join(analysis_parts) if analysis_parts else ""
    def _build_system_prompt(
        self,
        user_state: UserStateSummary,
        retrieved_context: List[str],
        mode: str = None,
        content_title: str = None,
        content_json: str = None,
        test_results: List[Dict[str, Any]] = None,
        code_content: CodeContent = None
    ) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        prompt_parts = [self.base_system_prompt]

        # æ·»åŠ ç¼–ç¨‹è¡Œä¸ºåˆ†ææç¤º
        coding_behavior_analysis = self._get_coding_behavior_analysis(user_state)
        if coding_behavior_analysis:
            prompt_parts.append(f"CODING BEHAVIOR ANALYSIS:\n{coding_behavior_analysis}")

        # æ·»åŠ æƒ…æ„Ÿç­–ç•¥
        emotion = user_state.emotion_state.get('current_sentiment', 'NEUTRAL')
        emotion_strategy = PromptGenerator._get_emotion_strategy(emotion)
        prompt_parts.append(f"STRATEGY: {emotion_strategy}")

        # æ·»åŠ ç”¨æˆ·çŠ¶æ€ä¿¡æ¯
        if user_state.is_new_user:
            prompt_parts.append("STUDENT INFO: This is a new student. Start with basic concepts and be extra patient.")
        else:
            # æ·»åŠ æ›´å¤šç”¨æˆ·çŠ¶æ€ä¿¡æ¯
            student_info_parts = ["STUDENT INFO: This is an existing student. Build upon previous knowledge."]

            # æ·»åŠ å­¦ä¹ è¿›åº¦ä¿¡æ¯
            if hasattr(user_state, 'bkt_models') and user_state.bkt_models:
                mastery_info = []
                for topic_key, bkt_model in user_state.bkt_models.items():
                    if isinstance(bkt_model, dict) and 'mastery_prob' in bkt_model:
                        mastery_prob = bkt_model['mastery_prob']
                    elif hasattr(bkt_model, 'mastery_prob'):
                        mastery_prob = bkt_model.mastery_prob
                    else:
                        continue

                    mastery_level = "beginner"
                    if mastery_prob > 0.8:
                        mastery_level = "advanced"
                    elif mastery_prob > 0.5:
                        mastery_level = "intermediate"
                    
                    mastery_info.append(f"{topic_key}: {mastery_level} (mastery: {mastery_prob:.2f})")
                
                if mastery_info:
                    student_info_parts.append(f"LEARNING PROGRESS: Student's mastery levels - {', '.join(mastery_info)}")

            # æ·»åŠ è¡Œä¸ºæ¨¡å¼ä¿¡æ¯
            if hasattr(user_state, 'behavior_patterns') and user_state.behavior_patterns:
                patterns = user_state.behavior_patterns
                pattern_info = []
                
                if 'error_frequency' in patterns:
                    pattern_info.append(f"error frequency: {patterns.get('error_frequency', 0):.2f}")
                if 'help_seeking_tendency' in patterns:
                    pattern_info.append(f"help-seeking tendency: {patterns.get('help_seeking_tendency', 0):.2f}")
                if 'learning_velocity' in patterns:
                    pattern_info.append(f"learning velocity: {patterns.get('learning_velocity', 0):.2f}")

                if pattern_info:
                    student_info_parts.append(f"BEHAVIOR METRICS: {', '.join(pattern_info)}")

            prompt_parts.append("\n".join(student_info_parts))

            # æ·»åŠ çŸ¥è¯†ç‚¹è®¿é—®å†å²
            if hasattr(user_state, 'behavior_patterns') and user_state.behavior_patterns.get('knowledge_level_history'):
                history = user_state.behavior_patterns['knowledge_level_history']
                if history:
                    topic_summaries = []
                    # Sort topics for consistent ordering
                    sorted_topics = sorted(history.keys())
                    
                    for topic_id in sorted_topics:
                        topic_history = history[topic_id]
                        if not topic_history:
                            continue
                        
                        topic_details = [f"  For Topic '{topic_id}':"]
                        # Sort levels for consistent ordering, filtering out non-numeric keys
                        sorted_levels = sorted([k for k in topic_history.keys() if k.isdigit()], key=lambda x: int(x))
                        
                        for level in sorted_levels:
                            stats = topic_history[level]
                            visits = stats.get('visits', 0)
                            duration_sec = stats.get('total_duration_ms', 0) / 1000
                            topic_details.append(f"  - Level {level}: Visited {visits} time(s), total duration {duration_sec:.1f} seconds.")
                        
                        if len(topic_details) > 1:
                            topic_summaries.append("\\n".join(topic_details))

                    if topic_summaries:
                        full_history_summary = "\\n".join(topic_summaries)
                        prompt_parts.append(f"""
LEARNING FOCUS: Please pay close attention to the student's behavior patterns to better understand their learning state. Remember that higher knowledge levels are more difficult.
- **Knowledge Level Exploration**: The student has explored the following knowledge levels. Use their visit order, frequency, and dwell time to infer their interests and potential difficulties.
{full_history_summary}""")

        # æ·»åŠ RAGä¸Šä¸‹æ–‡ (åœ¨ç”¨æˆ·çŠ¶æ€ä¿¡æ¯ä¹‹åï¼Œä»»åŠ¡ä¸Šä¸‹æ–‡ä¹‹å‰)
        if retrieved_context:
            formatted_context = "\n\n---\n\n".join(retrieved_context)
            prompt_parts.append(f"REFERENCE KNOWLEDGE: Use the following information from the knowledge base to answer the user's question accurately.\n\n{formatted_context}")
        else:
            prompt_parts.append("REFERENCE KNOWLEDGE: No relevant knowledge was retrieved from the knowledge base. Answer based on your general knowledge.")

        # æ·»åŠ ä»»åŠ¡ä¸Šä¸‹æ–‡å’Œåˆ†é˜¶æ®µdebugé€»è¾‘
        if mode == "test":
            prompt_parts.append("MODE: The student is in test mode. Guide them to find the answer themselves. Do not give the answer directly.")
            
            # ä½¿ç”¨ç»Ÿä¸€æç¤ºè¯æ¨¡ç‰ˆ
            question_count = 0
            user_code = ""
            error_message = ""
            
            if hasattr(user_state, 'behavior_patterns'):
                question_count = user_state.behavior_patterns.get(f"question_count_{content_title}", 0)
            
            # è·å–ä»£ç å’Œé”™è¯¯ä¿¡æ¯
            if code_content and hasattr(code_content, 'js'):
                user_code = code_content.js
            
            if test_results:
                # å°†æµ‹è¯•ç»“æœè½¬æ¢ä¸ºé”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
                error_message = json.dumps(test_results, indent=2, ensure_ascii=False)
            
            # æ ¼å¼åŒ–è°ƒè¯•æç¤ºè¯
            debug_prompt = self.debug_prompt_template.format(
                content_title=content_title or "Unknown",
                question_count=question_count,
                user_code=user_code,
                error_message=error_message
            )
            prompt_parts.append(debug_prompt)
        else:
            if mode == "learning":
                prompt_parts.append("MODE: The student is in learning mode. Provide detailed explanations and examples to help them understand the concepts.")
                
                # ä½¿ç”¨å­¦ä¹ æ¨¡å¼æç¤ºè¯æ¨¡ç‰ˆ
                mastery_level = "beginner"
                mastery_prob = 0.0
                
                # è·å–å½“å‰ä¸»é¢˜çš„æŒæ¡åº¦ä¿¡æ¯
                if hasattr(user_state, 'bkt_models') and user_state.bkt_models and content_title:
                    for topic_key, bkt_model in user_state.bkt_models.items():
                        if content_title.lower() in topic_key.lower():
                            if isinstance(bkt_model, dict) and 'mastery_prob' in bkt_model:
                                mastery_prob = bkt_model['mastery_prob']
                            elif hasattr(bkt_model, 'mastery_prob'):
                                mastery_prob = bkt_model.mastery_prob
                            break
                    
                    # ç¡®å®šæŒæ¡åº¦ç­‰çº§
                    if mastery_prob > 0.8:
                        mastery_level = "advanced"
                    elif mastery_prob > 0.5:
                        mastery_level = "intermediate"
                
                # æ ¼å¼åŒ–å­¦ä¹ æç¤ºè¯
                learning_prompt = self.learning_prompt_template.format(
                    content_title=content_title or "Unknown",
                    mastery_level=mastery_level,
                    mastery_prob=mastery_prob
                )
                prompt_parts.append(learning_prompt)
            else:
                # æ·»åŠ å†…å®¹æ ‡é¢˜ï¼ˆéå­¦ä¹ æ¨¡å¼ï¼‰
                if content_title:
                    prompt_parts.append(f"TOPIC: The current topic is '{content_title}'. Focus your explanations on this specific topic.")
        
        # æ·»åŠ å†…å®¹JSONï¼ˆå¦‚æœæä¾›ï¼‰
        if content_json:
            # ç¡®ä¿JSONå†…å®¹æ­£ç¡®ç¼–ç ï¼Œé¿å…Unicodeè½¬ä¹‰åºåˆ—é—®é¢˜
            try:
                # è§£æJSONå­—ç¬¦ä¸²
                content_dict = json.loads(content_json)
                # é‡æ–°åºåˆ—åŒ–ä¸ºæ ¼å¼åŒ–çš„JSONå­—ç¬¦ä¸²ï¼Œç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º
                formatted_content_json = json.dumps(content_dict, indent=2, ensure_ascii=False)
                prompt_parts.append(f"CONTENT DATA: Here is the detailed content data for the current topic. Use this to provide more specific and accurate guidance.\n{formatted_content_json}")
            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å†…å®¹
                prompt_parts.append(f"CONTENT DATA: Here is the detailed content data for the current topic. Use this to provide more specific and accurate guidance.\n{content_json}")

        return "\n\n".join(prompt_parts)

    @staticmethod
    def _get_emotion_strategy(emotion: str) -> str:
        """æ ¹æ®æƒ…æ„Ÿè·å–æ•™å­¦ç­–ç•¥"""
        strategies = {
            'FRUSTRATED': "The student seems frustrated. Your top priority is to validate their feelings and be encouraging. Acknowledge the difficulty before offering help. Use phrases like 'I can see why this is frustrating, it's a tough concept' or 'Let's take a step back and try a different angle'. Avoid saying 'it's easy' or dismissing their struggle.",
            'CONFUSED': "The student seems confused. Your first step is to ask questions to pinpoint the source of confusion (e.g., 'Where did I lose you?' or 'What part of that example felt unclear?'). Then, break down concepts into smaller, simpler steps. Use analogies and the simplest possible examples. Avoid jargon.",
            'EXCITED': "The student seems excited and engaged. Praise their curiosity and capitalize on their momentum. Challenge them with deeper explanations or a more complex problem. Connect the concept to a real-world application or a related advanced topic to broaden their perspective.",
            'NEUTRAL': "The student seems neutral. Maintain a clear, structured teaching approach, but proactively try to spark interest by relating the topic to a surprising fact or a practical application. Frequently check for understanding with specific questions like 'Can you explain that back to me in your own words?' or 'How would you apply this to...?'"
        }

        return strategies.get(emotion.upper(), strategies['NEUTRAL'])

    def _build_message_history(
        self,
        conversation_history: List[Dict[str, str]],
        code_context: CodeContent = None,
        user_message: str = ""
    ) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯å†å²"""
        messages = []

        # æ·»åŠ å†å²å¯¹è¯
        for msg in conversation_history:
            if isinstance(msg, dict) and 'role' in msg and 'content' in msg:
                messages.append({
                    "role": msg['role'],
                    "content": msg['content']
                })

        # æ„å»ºå½“å‰ç”¨æˆ·æ¶ˆæ¯
        current_user_content = user_message

        # å¦‚æœæœ‰ä»£ç ä¸Šä¸‹æ–‡ï¼Œæ·»åŠ åˆ°ç”¨æˆ·æ¶ˆæ¯ä¸­
        if code_context:
            code_section = self._format_code_context(code_context)
            current_user_content = f"{code_section}\n\nMy question is: {user_message}"

        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        if current_user_content.strip():
            messages.append({
                "role": "user",
                "content": current_user_content
            })

        return messages

    def _format_code_context(self, code_context: CodeContent) -> str:
        """æ ¼å¼åŒ–ä»£ç ä¸Šä¸‹æ–‡"""
        parts = []

        if code_context.html.strip():
            parts.append(f"HTML Code:\n```html\n{code_context.html}\n```")

        if code_context.css.strip():
            parts.append(f"CSS Code:\n```css\n{code_context.css}\n```")

        if code_context.js.strip():
            parts.append(f"JavaScript Code:\n```javascript\n{code_context.js}\n```")

        if parts:
            return "Here is my current code:\n\n" + "\n\n".join(parts)
        else:
            return ""


# åˆ›å»ºå•ä¾‹å®ä¾‹
prompt_generator = PromptGenerator()